{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 27\n",
    "\n",
    "# Text Classification\n",
    "\n",
    "# Dataset-1 \n",
    "\n",
    "fetch_20newgroups\n",
    "\n",
    "\n",
    "multiclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 7532)"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Working with the first data set\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=21)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=21)\n",
    "\n",
    "len(newsgroups_train.data), len(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re, string\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(newsgroups_train.data, newsgroups_train.target, train_size=0.8, test_size=0.2)\n",
    "print(len(x_train))\n",
    "\n",
    "x_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(file):\n",
    "    text_content = []\n",
    "    exclude = string.punctuation\n",
    "    exclude = exclude.replace(\"-\", \"\")\n",
    "    pattern = r\"[{}]\".format(exclude)\n",
    "\n",
    "    for data in file :\n",
    "        text = re.sub(r\"(<br\\s*/><br\\s*/>)\", \" \", str(data))\n",
    "        text = re.sub(pattern, \"\", str(text))\n",
    "        text_content.append(text.lower())\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 7532)"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = preprocessing(x_train)\n",
    "x_val = preprocessing(x_val)\n",
    "y_train = preprocessing(y_train)\n",
    "y_val = preprocessing(y_val)\n",
    "\n",
    "x_test = preprocessing(x_test)\n",
    "y_test = preprocessing(y_test)\n",
    "len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 99866)\n",
      "(7532, 99866)\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer (Not Necessary)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words=None, ngram_range=(1,1), binary=True)\n",
    "#print(vectorizer)\n",
    "\n",
    "train_set = vectorizer.fit_transform(x_train)\n",
    "val_set = vectorizer.transform(x_val)\n",
    "test_set = vectorizer.transform(x_test)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 99866)\n",
      "(2263, 99866)\n",
      "(7532, 99866)\n"
     ]
    }
   ],
   "source": [
    "#TFIDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "train_idf = tf_idf_vectorizer.fit_transform(x_train)\n",
    "val_idf = tf_idf_vectorizer.transform(x_val)\n",
    "test_idf = tf_idf_vectorizer.transform(x_test)\n",
    "\n",
    "print(train_idf.shape)\n",
    "print(val_idf.shape)\n",
    "print(test_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 99866)\n",
      "(2263, 99866)\n",
      "(7532, 99866)\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer_train = Normalizer().fit(X=vectors_train_idf)\n",
    "train_norm = normalizer_train.transform(train_idf)\n",
    "val_norm = normalizer_train.transform(val_idf)\n",
    "test_norm = normalizer_train.transform(test_idf)\n",
    "\n",
    "print(train_norm.shape)\n",
    "print(val_norm.shape)\n",
    "print(test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100.0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.055 (+/-0.001) for {'C': 0.001}\n",
      "0.359 (+/-0.017) for {'C': 0.01}\n",
      "0.591 (+/-0.025) for {'C': 0.1}\n",
      "0.712 (+/-0.012) for {'C': 1.0}\n",
      "0.733 (+/-0.020) for {'C': 10.0}\n",
      "0.733 (+/-0.022) for {'C': 100.0}\n",
      "0.733 (+/-0.022) for {'C': 1000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.018 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.69474   0.70213   0.69841        94\n",
      "           1    0.68293   0.65116   0.66667       129\n",
      "          10    0.86325   0.84167   0.85232       120\n",
      "          11    0.86139   0.72500   0.78733       120\n",
      "          12    0.71304   0.74545   0.72889       110\n",
      "          13    0.86139   0.75652   0.80556       115\n",
      "          14    0.79710   0.76923   0.78292       143\n",
      "          15    0.75676   0.76712   0.76190       146\n",
      "          16    0.74747   0.82222   0.78307        90\n",
      "          17    0.74576   0.77193   0.75862       114\n",
      "          18    0.67033   0.63542   0.65241        96\n",
      "          19    0.50000   0.36250   0.42029        80\n",
      "           2    0.61111   0.69474   0.65025        95\n",
      "           3    0.67368   0.59813   0.63366       107\n",
      "           4    0.65049   0.69072   0.67000        97\n",
      "           5    0.78632   0.74194   0.76349       124\n",
      "           6    0.81416   0.73600   0.77311       125\n",
      "           7    0.46597   0.74167   0.57235       120\n",
      "           8    0.71875   0.79310   0.75410       116\n",
      "           9    0.84615   0.72131   0.77876       122\n",
      "\n",
      "   micro avg    0.72072   0.72072   0.72072      2263\n",
      "   macro avg    0.72304   0.71340   0.71470      2263\n",
      "weighted avg    0.73089   0.72072   0.72235      2263\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100.0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.055 (+/-0.001) for {'C': 0.001}\n",
      "0.360 (+/-0.023) for {'C': 0.01}\n",
      "0.591 (+/-0.026) for {'C': 0.1}\n",
      "0.711 (+/-0.012) for {'C': 1.0}\n",
      "0.733 (+/-0.019) for {'C': 10.0}\n",
      "0.733 (+/-0.022) for {'C': 100.0}\n",
      "0.733 (+/-0.025) for {'C': 1000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.022 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.68750   0.70213   0.69474        94\n",
      "           1    0.68293   0.65116   0.66667       129\n",
      "          10    0.86325   0.84167   0.85232       120\n",
      "          11    0.86139   0.72500   0.78733       120\n",
      "          12    0.71304   0.74545   0.72889       110\n",
      "          13    0.86139   0.75652   0.80556       115\n",
      "          14    0.79710   0.76923   0.78292       143\n",
      "          15    0.75676   0.76712   0.76190       146\n",
      "          16    0.74747   0.82222   0.78307        90\n",
      "          17    0.74576   0.77193   0.75862       114\n",
      "          18    0.67778   0.63542   0.65591        96\n",
      "          19    0.50000   0.36250   0.42029        80\n",
      "           2    0.61111   0.69474   0.65025        95\n",
      "           3    0.67368   0.59813   0.63366       107\n",
      "           4    0.65686   0.69072   0.67337        97\n",
      "           5    0.78632   0.74194   0.76349       124\n",
      "           6    0.82143   0.73600   0.77637       125\n",
      "           7    0.46875   0.75000   0.57692       120\n",
      "           8    0.71875   0.79310   0.75410       116\n",
      "           9    0.84762   0.72951   0.78414       122\n",
      "\n",
      "   micro avg    0.72161   0.72161   0.72161      2263\n",
      "   macro avg    0.72394   0.71422   0.71553      2263\n",
      "weighted avg    0.73180   0.72161   0.72320      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "clf = LogisticRegression(multi_class = 'multinomial', solver='saga', max_iter=4000)\n",
    "\n",
    "tuned_parameters={\"C\":np.logspace(-3,3,7)}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "#Tried for the following as well for parameters, L2 was better in this case\n",
    "#\"penalty\":[\"l1\",\"l2\"]}#, \"dual\": [\"True\", \"False\"], \"max_iter\": np.power(10.0, np.arange(-10, 10))}\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf_log=GridSearchCV(clf,tuned_parameters,cv=10)\n",
    "    clf_log.fit(train_norm, y_train)\n",
    "\n",
    "    t0=time.time()\n",
    "    print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf_log.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf_log.cv_results_['mean_test_score']\n",
    "    stds = clf_log.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf_log.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    t1=time.time()\n",
    "    y_pred = clf_log.predict(val_norm)\n",
    "    print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "    print(metrics.classification_report(y_val, y_pred, digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'C': 100.0}\n",
      "accurac y : 0.7333996243509004\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hyperparameters :(best parameters) \",clf_log.best_params_)\n",
    "print(\"accurac y :\",clf_log.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 855.665 s\n",
      "predict time: 855.685 s\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Val set\n",
    "clf = LogisticRegression(C=100,penalty=\"l2\", multi_class = 'multinomial', solver='saga', max_iter=4000)\n",
    "clf.fit(train_norm, y_train)\n",
    "print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "t2=time.time()\n",
    "y_pred = clf.predict(val_norm)\n",
    "print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "#print(metrics.classification_report(y_val, y_pred, digits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.7211665930181176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69        94\n",
      "           1       0.68      0.65      0.67       129\n",
      "          10       0.86      0.84      0.85       120\n",
      "          11       0.86      0.72      0.79       120\n",
      "          12       0.71      0.75      0.73       110\n",
      "          13       0.84      0.76      0.80       115\n",
      "          14       0.80      0.76      0.78       143\n",
      "          15       0.76      0.77      0.76       146\n",
      "          16       0.75      0.82      0.78        90\n",
      "          17       0.75      0.77      0.76       114\n",
      "          18       0.68      0.64      0.66        96\n",
      "          19       0.50      0.36      0.42        80\n",
      "           2       0.61      0.69      0.65        95\n",
      "           3       0.68      0.61      0.64       107\n",
      "           4       0.66      0.69      0.68        97\n",
      "           5       0.79      0.74      0.76       124\n",
      "           6       0.81      0.74      0.77       125\n",
      "           7       0.47      0.74      0.57       120\n",
      "           8       0.71      0.79      0.75       116\n",
      "           9       0.85      0.73      0.78       122\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      2263\n",
      "   macro avg       0.72      0.71      0.72      2263\n",
      "weighted avg       0.73      0.72      0.72      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_val, y_pred))\n",
    "print(metrics.classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time for test: 0.048 s\n",
      "accuracy:\n",
      "0.6623738714816781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.48      0.48       319\n",
      "           1       0.64      0.66      0.65       389\n",
      "          10       0.87      0.84      0.86       399\n",
      "          11       0.79      0.68      0.73       396\n",
      "          12       0.60      0.60      0.60       393\n",
      "          13       0.73      0.73      0.73       396\n",
      "          14       0.72      0.70      0.71       394\n",
      "          15       0.65      0.72      0.68       398\n",
      "          16       0.56      0.64      0.60       364\n",
      "          17       0.79      0.69      0.74       376\n",
      "          18       0.51      0.44      0.47       310\n",
      "          19       0.41      0.35      0.38       251\n",
      "           2       0.59      0.61      0.60       394\n",
      "           3       0.61      0.61      0.61       392\n",
      "           4       0.68      0.69      0.68       385\n",
      "           5       0.81      0.63      0.71       395\n",
      "           6       0.79      0.76      0.78       390\n",
      "           7       0.48      0.75      0.59       396\n",
      "           8       0.76      0.72      0.74       398\n",
      "           9       0.80      0.76      0.78       397\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      7532\n",
      "   macro avg       0.66      0.65      0.65      7532\n",
      "weighted avg       0.67      0.66      0.66      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Test set\n",
    "t2=time.time()\n",
    "y_pred = clf.predict(test_norm)\n",
    "print (\"predict time for test:\", round(time.time()-t2, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'fit_prior': 'true'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.743 (+/-0.029) for {'alpha': 0.001, 'fit_prior': 'true'}\n",
      "0.743 (+/-0.029) for {'alpha': 0.001, 'fit_prior': 'false'}\n",
      "0.752 (+/-0.021) for {'alpha': 0.01, 'fit_prior': 'true'}\n",
      "0.752 (+/-0.021) for {'alpha': 0.01, 'fit_prior': 'false'}\n",
      "0.728 (+/-0.027) for {'alpha': 0.1, 'fit_prior': 'true'}\n",
      "0.728 (+/-0.027) for {'alpha': 0.1, 'fit_prior': 'false'}\n",
      "0.648 (+/-0.024) for {'alpha': 1.0, 'fit_prior': 'true'}\n",
      "0.648 (+/-0.024) for {'alpha': 1.0, 'fit_prior': 'false'}\n",
      "0.463 (+/-0.026) for {'alpha': 10.0, 'fit_prior': 'true'}\n",
      "0.463 (+/-0.026) for {'alpha': 10.0, 'fit_prior': 'false'}\n",
      "0.303 (+/-0.024) for {'alpha': 100.0, 'fit_prior': 'true'}\n",
      "0.303 (+/-0.024) for {'alpha': 100.0, 'fit_prior': 'false'}\n",
      "0.055 (+/-0.001) for {'alpha': 1000.0, 'fit_prior': 'true'}\n",
      "0.055 (+/-0.001) for {'alpha': 1000.0, 'fit_prior': 'false'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.021 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70588   0.63830   0.67039        94\n",
      "           1    0.69167   0.64341   0.66667       129\n",
      "          10    0.90909   0.91667   0.91286       120\n",
      "          11    0.75781   0.80833   0.78226       120\n",
      "          12    0.80392   0.74545   0.77358       110\n",
      "          13    0.87387   0.84348   0.85841       115\n",
      "          14    0.88281   0.79021   0.83395       143\n",
      "          15    0.71658   0.91781   0.80480       146\n",
      "          16    0.65546   0.86667   0.74641        90\n",
      "          17    0.79032   0.85965   0.82353       114\n",
      "          18    0.72340   0.70833   0.71579        96\n",
      "          19    0.80769   0.26250   0.39623        80\n",
      "           2    0.42446   0.62105   0.50427        95\n",
      "           3    0.61475   0.70093   0.65502       107\n",
      "           4    0.72277   0.75258   0.73737        97\n",
      "           5    0.80469   0.83065   0.81746       124\n",
      "           6    0.90816   0.71200   0.79821       125\n",
      "           7    0.76415   0.67500   0.71681       120\n",
      "           8    0.77049   0.81034   0.78992       116\n",
      "           9    0.93137   0.77869   0.84821       122\n",
      "\n",
      "   micro avg    0.75563   0.75563   0.75563      2263\n",
      "   macro avg    0.76297   0.74410   0.74261      2263\n",
      "weighted avg    0.77011   0.75563   0.75398      2263\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'fit_prior': 'true'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.743 (+/-0.029) for {'alpha': 0.001, 'fit_prior': 'true'}\n",
      "0.743 (+/-0.029) for {'alpha': 0.001, 'fit_prior': 'false'}\n",
      "0.752 (+/-0.021) for {'alpha': 0.01, 'fit_prior': 'true'}\n",
      "0.752 (+/-0.021) for {'alpha': 0.01, 'fit_prior': 'false'}\n",
      "0.728 (+/-0.027) for {'alpha': 0.1, 'fit_prior': 'true'}\n",
      "0.728 (+/-0.027) for {'alpha': 0.1, 'fit_prior': 'false'}\n",
      "0.648 (+/-0.024) for {'alpha': 1.0, 'fit_prior': 'true'}\n",
      "0.648 (+/-0.024) for {'alpha': 1.0, 'fit_prior': 'false'}\n",
      "0.463 (+/-0.026) for {'alpha': 10.0, 'fit_prior': 'true'}\n",
      "0.463 (+/-0.026) for {'alpha': 10.0, 'fit_prior': 'false'}\n",
      "0.303 (+/-0.024) for {'alpha': 100.0, 'fit_prior': 'true'}\n",
      "0.303 (+/-0.024) for {'alpha': 100.0, 'fit_prior': 'false'}\n",
      "0.055 (+/-0.001) for {'alpha': 1000.0, 'fit_prior': 'true'}\n",
      "0.055 (+/-0.001) for {'alpha': 1000.0, 'fit_prior': 'false'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.025 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.70588   0.63830   0.67039        94\n",
      "           1    0.69167   0.64341   0.66667       129\n",
      "          10    0.90909   0.91667   0.91286       120\n",
      "          11    0.75781   0.80833   0.78226       120\n",
      "          12    0.80392   0.74545   0.77358       110\n",
      "          13    0.87387   0.84348   0.85841       115\n",
      "          14    0.88281   0.79021   0.83395       143\n",
      "          15    0.71658   0.91781   0.80480       146\n",
      "          16    0.65546   0.86667   0.74641        90\n",
      "          17    0.79032   0.85965   0.82353       114\n",
      "          18    0.72340   0.70833   0.71579        96\n",
      "          19    0.80769   0.26250   0.39623        80\n",
      "           2    0.42446   0.62105   0.50427        95\n",
      "           3    0.61475   0.70093   0.65502       107\n",
      "           4    0.72277   0.75258   0.73737        97\n",
      "           5    0.80469   0.83065   0.81746       124\n",
      "           6    0.90816   0.71200   0.79821       125\n",
      "           7    0.76415   0.67500   0.71681       120\n",
      "           8    0.77049   0.81034   0.78992       116\n",
      "           9    0.93137   0.77869   0.84821       122\n",
      "\n",
      "   micro avg    0.75563   0.75563   0.75563      2263\n",
      "   macro avg    0.76297   0.74410   0.74261      2263\n",
      "weighted avg    0.77011   0.75563   0.75398      2263\n",
      "\n",
      "tuned hyperparameters :(best parameters)  {'alpha': 0.01, 'fit_prior': 'true'}\n",
      "accurac y : 0.7518506242404154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "n_folds = 10\n",
    "tuned_parameters = {\"alpha\":np.logspace(-3,3,7), \"fit_prior\":[\"true\",\"false\"]}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf_nb=GridSearchCV(clf2,tuned_parameters,cv=10)\n",
    "    clf_nb.fit(train_norm, y_train)\n",
    "\n",
    "    t0=time.time()\n",
    "    print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf_nb.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf_nb.cv_results_['mean_test_score']\n",
    "    stds = clf_nb.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf_nb.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    t1=time.time()\n",
    "    y_pred = clf_nb.predict(val_norm)\n",
    "    print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "    print(metrics.classification_report(y_val, y_pred, digits = 5))\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_nb.best_params_)\n",
    "print(\"accurac y :\",clf_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 459.855 s\n",
      "predict time: 459.867 s\n",
      "accuracy:\n",
      "0.755634114007954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67        94\n",
      "           1       0.69      0.64      0.67       129\n",
      "          10       0.91      0.92      0.91       120\n",
      "          11       0.76      0.81      0.78       120\n",
      "          12       0.80      0.75      0.77       110\n",
      "          13       0.87      0.84      0.86       115\n",
      "          14       0.88      0.79      0.83       143\n",
      "          15       0.72      0.92      0.80       146\n",
      "          16       0.66      0.87      0.75        90\n",
      "          17       0.79      0.86      0.82       114\n",
      "          18       0.72      0.71      0.72        96\n",
      "          19       0.81      0.26      0.40        80\n",
      "           2       0.42      0.62      0.50        95\n",
      "           3       0.61      0.70      0.66       107\n",
      "           4       0.72      0.75      0.74        97\n",
      "           5       0.80      0.83      0.82       124\n",
      "           6       0.91      0.71      0.80       125\n",
      "           7       0.76      0.68      0.72       120\n",
      "           8       0.77      0.81      0.79       116\n",
      "           9       0.93      0.78      0.85       122\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2263\n",
      "   macro avg       0.76      0.74      0.74      2263\n",
      "weighted avg       0.77      0.76      0.75      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Validation set\n",
    "MultinomialNB(alpha=\"0.01\")\n",
    "clf_nb.fit(train_norm, y_train)\n",
    "print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "t2=time.time()\n",
    "y_pred2 = clf_nb.predict(val_norm)\n",
    "print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_val, y_pred2))\n",
    "print(metrics.classification_report(y_val, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time for test: 0.041 s\n",
      "accuracy:\n",
      "0.688396176314392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.48       319\n",
      "           1       0.66      0.69      0.67       389\n",
      "          10       0.92      0.90      0.91       399\n",
      "          11       0.68      0.75      0.71       396\n",
      "          12       0.70      0.58      0.63       393\n",
      "          13       0.82      0.80      0.81       396\n",
      "          14       0.77      0.77      0.77       394\n",
      "          15       0.55      0.86      0.67       398\n",
      "          16       0.54      0.73      0.62       364\n",
      "          17       0.81      0.77      0.79       376\n",
      "          18       0.59      0.43      0.50       310\n",
      "          19       0.48      0.18      0.26       251\n",
      "           2       0.42      0.54      0.47       394\n",
      "           3       0.58      0.70      0.63       392\n",
      "           4       0.69      0.70      0.69       385\n",
      "           5       0.80      0.73      0.77       395\n",
      "           6       0.84      0.68      0.75       390\n",
      "           7       0.78      0.71      0.74       396\n",
      "           8       0.75      0.72      0.73       398\n",
      "           9       0.91      0.80      0.85       397\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      7532\n",
      "   macro avg       0.69      0.67      0.67      7532\n",
      "weighted avg       0.70      0.69      0.69      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Test set\n",
    "t2=time.time()\n",
    "y_pred2 = clf_nb.predict(test_norm)\n",
    "print (\"predict time for test:\", round(time.time()-t2, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_test, y_pred2))\n",
    "print(metrics.classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
