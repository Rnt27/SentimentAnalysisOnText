{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 27\n",
    "\n",
    "# Text Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset-2\n",
    "\n",
    "# Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second data Set\n",
    "\n",
    "def Open_Files (path):\n",
    "    content = []\n",
    "    file_names = os.listdir(path)\n",
    "    for file in file_names:\n",
    "        t = path + file\n",
    "        content.append(open(t, encoding ='utf-8').read())  #English Text\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "training_pos = Open_Files('C:\\\\Users\\\\Owner\\Documents\\\\Python\\\\Assignment2\\\\Data\\\\aclImdb_v1\\\\aclImdb\\\\train\\\\pos\\\\')\n",
    "training_neg = Open_Files('C:\\\\Users\\\\Owner\\\\Documents\\\\Python\\\\Assignment2\\\\Data\\\\aclImdb_v1\\\\aclImdb\\\\train\\\\neg\\\\')\n",
    "test_pos = Open_Files('C:\\\\Users\\\\Owner\\\\Documents\\\\Python\\\\Assignment2\\\\Data\\\\aclImdb_v1\\\\aclImdb\\\\test\\\\pos\\\\')\n",
    "test_neg = Open_Files ('C:\\\\Users\\\\Owner\\\\Documents\\\\Python\\\\Assignment2\\\\Data\\\\aclImdb_v1\\\\aclImdb\\\\test\\\\neg\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(file):\n",
    "    text_content = []\n",
    "    exclude = string.punctuation\n",
    "    exclude = exclude.replace(\"-\", \"\")\n",
    "    pattern = r\"[{}]\".format(exclude)\n",
    "\n",
    "    for data in file :\n",
    "        text = re.sub(r\"(<br\\s*/><br\\s*/>)\", \" \", str(data))\n",
    "        text = re.sub(pattern, \"\", str(text))\n",
    "        text_content.append(text.lower())\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Data Spliting and Labelization \n",
    "training_CrossValidation = training_pos + training_neg\n",
    "x_train2 = training_pos[:10000] + training_neg[:10000]\n",
    "x_train2 = preprocessing(x_train2)\n",
    "x_val2 = training_pos [10000:] + training_neg[10000:]\n",
    "x_val2 = preprocessing(x_val2)\n",
    "x_test2 = test_pos + test_neg\n",
    "x_test2 = preprocessing(x_test2)\n",
    "#labelization\n",
    "y_train2 = np.append(np.ones(10000), np.zeros(10000))\n",
    "y_val2 = np.append(np.ones(2500), np.zeros(2500))\n",
    "y_test2 = np.append(np.ones(12500), np.zeros(12500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 84708)\n",
      "(25000, 84708)\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer (Not Necessary)\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words=None, ngram_range=(1,1), binary=True) \n",
    "\n",
    "train_set2 = vectorizer.fit_transform(x_train2)\n",
    "val_set2 = vectorizer.transform(x_val2)\n",
    "test_set2 = vectorizer.transform(x_test2)\n",
    "\n",
    "print(train_set2.shape)\n",
    "print(test_set2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 84708)\n",
      "(5000, 84708)\n",
      "(25000, 84708)\n"
     ]
    }
   ],
   "source": [
    "#TFIDF Vectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "train_idf2 = tf_idf_vectorizer.fit_transform(x_train2)\n",
    "val_idf2 = tf_idf_vectorizer.transform(x_val2)\n",
    "test_idf2 = tf_idf_vectorizer.transform(x_test2)\n",
    "\n",
    "print(train_idf2.shape)\n",
    "print(val_idf2.shape)\n",
    "print(test_idf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 84708)\n",
      "(5000, 84708)\n",
      "(25000, 84708)\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "normalizer_train = Normalizer().fit(X=vectors_train_idf)\n",
    "train_norm2 = normalizer_train.transform(train_idf2)\n",
    "val_norm2 = normalizer_train.transform(val_idf2)\n",
    "test_norm2 = normalizer_train.transform(test_idf2)\n",
    "\n",
    "print(train_norm2.shape)\n",
    "print(val_norm2.shape)\n",
    "print(test_norm2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.769 (+/-0.026) for {'C': 0.001}\n",
      "0.784 (+/-0.023) for {'C': 0.01}\n",
      "0.834 (+/-0.017) for {'C': 0.1}\n",
      "0.865 (+/-0.024) for {'C': 1.0}\n",
      "0.859 (+/-0.029) for {'C': 10.0}\n",
      "0.847 (+/-0.029) for {'C': 100.0}\n",
      "0.841 (+/-0.032) for {'C': 1000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.016 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.87232   0.88000   0.87614      2500\n",
      "         1.0    0.87893   0.87120   0.87505      2500\n",
      "\n",
      "   micro avg    0.87560   0.87560   0.87560      5000\n",
      "   macro avg    0.87563   0.87560   0.87560      5000\n",
      "weighted avg    0.87563   0.87560   0.87560      5000\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.769 (+/-0.026) for {'C': 0.001}\n",
      "0.785 (+/-0.024) for {'C': 0.01}\n",
      "0.834 (+/-0.017) for {'C': 0.1}\n",
      "0.865 (+/-0.024) for {'C': 1.0}\n",
      "0.859 (+/-0.029) for {'C': 10.0}\n",
      "0.847 (+/-0.029) for {'C': 100.0}\n",
      "0.841 (+/-0.031) for {'C': 1000.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.003 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.87232   0.88000   0.87614      2500\n",
      "         1.0    0.87893   0.87120   0.87505      2500\n",
      "\n",
      "   micro avg    0.87560   0.87560   0.87560      5000\n",
      "   macro avg    0.87563   0.87560   0.87560      5000\n",
      "weighted avg    0.87563   0.87560   0.87560      5000\n",
      "\n",
      "tuned hyperparameters :(best parameters)  {'C': 1.0}\n",
      "accurac y : 0.86475\n"
     ]
    }
   ],
   "source": [
    "clf3 = LogisticRegression(multi_class = 'ovr', solver='saga', max_iter=1000)\n",
    "\n",
    "tuned_parameters={\"C\":np.logspace(-3,3,7)}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "#Tried for the following as well for parameters, L2 was better in this case\n",
    "#\"penalty\":[\"l1\",\"l2\"]}#, \"dual\": [\"True\", \"False\"], \"max_iter\": np.power(10.0, np.arange(-10, 10))}\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf_log2=GridSearchCV(clf3,tuned_parameters,cv=10)\n",
    "    clf_log2.fit(train_norm2, y_train2)\n",
    "\n",
    "    t0=time.time()\n",
    "    print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf_log2.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf_log2.cv_results_['mean_test_score']\n",
    "    stds = clf_log2.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf_log2.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    t1=time.time()\n",
    "    y_pred = clf_log2.predict(val_norm2)\n",
    "    print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "    print(metrics.classification_report(y_val2, y_pred, digits = 5))\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_log2.best_params_)\n",
    "print(\"accurac y :\",clf_log2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 263.71 s\n",
      "predict time: 263.713 s\n",
      "accuracy:\n",
      "0.8756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.88      2500\n",
      "         1.0       0.88      0.87      0.88      2500\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Val set\n",
    "clf3 = LogisticRegression(C=1.0,penalty=\"l2\", multi_class = 'ovr', solver='saga', max_iter=1000)\n",
    "clf3.fit(train_norm2, y_train2)\n",
    "print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "t2=time.time()\n",
    "y_pred3 = clf3.predict(val_norm2)\n",
    "print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_val2, y_pred3))\n",
    "print(metrics.classification_report(y_val2, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time: 0.012 s\n",
      "accuracy:\n",
      "0.88084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88     12500\n",
      "         1.0       0.88      0.88      0.88     12500\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Test set\n",
    "t2=time.time()\n",
    "y_pred3 = clf3.predict(test_norm2)\n",
    "print (\"predict time:\", round(time.time()-t2, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_test2, y_pred3))\n",
    "print(metrics.classification_report(y_test2, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 1.0, 'fit_prior': 'true'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.696 (+/-0.067) for {'alpha': 0.001, 'fit_prior': 'true'}\n",
      "0.696 (+/-0.067) for {'alpha': 0.001, 'fit_prior': 'false'}\n",
      "0.730 (+/-0.066) for {'alpha': 0.01, 'fit_prior': 'true'}\n",
      "0.730 (+/-0.066) for {'alpha': 0.01, 'fit_prior': 'false'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.1, 'fit_prior': 'true'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.1, 'fit_prior': 'false'}\n",
      "0.807 (+/-0.041) for {'alpha': 1.0, 'fit_prior': 'true'}\n",
      "0.807 (+/-0.041) for {'alpha': 1.0, 'fit_prior': 'false'}\n",
      "0.806 (+/-0.035) for {'alpha': 10.0, 'fit_prior': 'true'}\n",
      "0.806 (+/-0.035) for {'alpha': 10.0, 'fit_prior': 'false'}\n",
      "0.747 (+/-0.033) for {'alpha': 100.0, 'fit_prior': 'true'}\n",
      "0.747 (+/-0.033) for {'alpha': 100.0, 'fit_prior': 'false'}\n",
      "0.720 (+/-0.036) for {'alpha': 1000.0, 'fit_prior': 'true'}\n",
      "0.720 (+/-0.036) for {'alpha': 1000.0, 'fit_prior': 'false'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.007 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.76611   0.88440   0.82102      2500\n",
      "         1.0    0.86329   0.73000   0.79107      2500\n",
      "\n",
      "   micro avg    0.80720   0.80720   0.80720      5000\n",
      "   macro avg    0.81470   0.80720   0.80604      5000\n",
      "weighted avg    0.81470   0.80720   0.80604      5000\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "training time: 0.0 s\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 1.0, 'fit_prior': 'true'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.696 (+/-0.067) for {'alpha': 0.001, 'fit_prior': 'true'}\n",
      "0.696 (+/-0.067) for {'alpha': 0.001, 'fit_prior': 'false'}\n",
      "0.730 (+/-0.066) for {'alpha': 0.01, 'fit_prior': 'true'}\n",
      "0.730 (+/-0.066) for {'alpha': 0.01, 'fit_prior': 'false'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.1, 'fit_prior': 'true'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.1, 'fit_prior': 'false'}\n",
      "0.807 (+/-0.041) for {'alpha': 1.0, 'fit_prior': 'true'}\n",
      "0.807 (+/-0.041) for {'alpha': 1.0, 'fit_prior': 'false'}\n",
      "0.806 (+/-0.035) for {'alpha': 10.0, 'fit_prior': 'true'}\n",
      "0.806 (+/-0.035) for {'alpha': 10.0, 'fit_prior': 'false'}\n",
      "0.747 (+/-0.033) for {'alpha': 100.0, 'fit_prior': 'true'}\n",
      "0.747 (+/-0.033) for {'alpha': 100.0, 'fit_prior': 'false'}\n",
      "0.720 (+/-0.036) for {'alpha': 1000.0, 'fit_prior': 'true'}\n",
      "0.720 (+/-0.036) for {'alpha': 1000.0, 'fit_prior': 'false'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "predict time: 0.007 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.76611   0.88440   0.82102      2500\n",
      "         1.0    0.86329   0.73000   0.79107      2500\n",
      "\n",
      "   micro avg    0.80720   0.80720   0.80720      5000\n",
      "   macro avg    0.81470   0.80720   0.80604      5000\n",
      "weighted avg    0.81470   0.80720   0.80604      5000\n",
      "\n",
      "tuned hyperparameters :(best parameters)  {'alpha': 1.0, 'fit_prior': 'true'}\n",
      "accurac y : 0.80695\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "tuned_parameters = {\"alpha\":np.logspace(-3,3,7), \"fit_prior\":[\"true\",\"false\"]}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "clf4 = MultinomialNB()\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf_nb2=GridSearchCV(clf4,tuned_parameters,cv=10)\n",
    "    clf_nb2.fit(train_norm2, y_train2)\n",
    "\n",
    "    t0=time.time()\n",
    "    print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf_nb2.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf_nb2.cv_results_['mean_test_score']\n",
    "    stds = clf_nb2.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf_nb2.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    t1=time.time()\n",
    "    y_pred4 = clf_nb2.predict(val_norm2)\n",
    "    print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "    print(metrics.classification_report(y_val2, y_pred4, digits = 5))\n",
    "\n",
    "print(\"tuned hyperparameters :(best parameters) \",clf_nb2.best_params_)\n",
    "print(\"accurac y :\",clf_nb2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 79.099 s\n",
      "predict time: 79.103 s\n",
      "accuracy:\n",
      "0.8072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.88      0.82      2500\n",
      "         1.0       0.86      0.73      0.79      2500\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Validation set\n",
    "MultinomialNB(alpha=\"1.0\")\n",
    "clf_nb2.fit(train_norm2, y_train2)\n",
    "print (\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "t2=time.time()\n",
    "y_pred4 = clf_nb2.predict(val_norm2)\n",
    "print (\"predict time:\", round(time.time()-t1, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_val2, y_pred4))\n",
    "print(metrics.classification_report(y_val2, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict time for test: 0.026 s\n",
      "accuracy:\n",
      "0.83028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84     12500\n",
      "         1.0       0.88      0.76      0.82     12500\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Optimal Solution\n",
    "#Test set\n",
    "t2=time.time()\n",
    "y_pred4 = clf_nb2.predict(test_norm2)\n",
    "print (\"predict time for test:\", round(time.time()-t2, 3), \"s\")\n",
    "print(\"accuracy:\")\n",
    "print(metrics.accuracy_score(y_test2, y_pred4))\n",
    "print(metrics.classification_report(y_test2, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
